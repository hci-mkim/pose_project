{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to C:\\Users\\min11/.cache\\torch\\hub\\checkpoints\\maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd2f6c1dfff4a0ca4bd8fadc9337e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=178090079.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\rcnnpose\\estimator.py:60: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:882.)\n",
      "  for i in (dictionary['labels'] == label).nonzero().view(-1):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nose  eye_l  eye_r  ear_l  ear_r  ankle_r\n",
      "x    76     77     70     55     56       66\n",
      "y    45     38     36     37     37      245\n",
      "   nose  eye_l  eye_r  ear_l  ear_r  ankle_r\n",
      "x    91     93     90     73     73       82\n",
      "y    46     38     37     30     30      234\n",
      "   nose  eye_l  eye_r  ear_l  ear_r  ankle_r\n",
      "x   104    108    105     93     94       88\n",
      "y    31     22     22      2      2      240\n",
      "   nose  eye_l  eye_r  ear_l  ear_r  ankle_r\n",
      "x   119    120    114    102    103      100\n",
      "y    23     14     14     12     12      250\n",
      "   nose  eye_l  eye_r  ear_l  ear_r  ankle_r\n",
      "x    96     98     96     76     76       84\n",
      "y    46     37     35     26     26      253\n",
      "   nose  eye_l  eye_r  ear_l  ear_r  ankle_r\n",
      "x   108    109    106     90     92       79\n",
      "y    36     28     28     27     28      248\n",
      "   nose  eye_l  eye_r  ear_l  ear_r  ankle_r\n",
      "x   112    107    109     94     97       91\n",
      "y    26     50     18     18     17      245\n",
      "   nose  eye_l  eye_r  ear_l  ear_r  ankle_r\n",
      "x   119    119    115    100    100       89\n",
      "y    27     21     19     19     20      247\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd;\n",
    "import time;\n",
    "import cv2\n",
    "import numpy as np\n",
    "from rcnnpose.estimator import BodyPoseEstimator\n",
    "from rcnnpose.utils import draw_body_connections, draw_keypoints, draw_masks\n",
    "\n",
    "# start = time.time();\n",
    "estimator = BodyPoseEstimator(pretrained=True);\n",
    "# print(f\"Estimator Load time : {time.time()-start}\\n\");\n",
    "# times = [];\n",
    "\n",
    "def main(input_img, outfile):\n",
    "#     start = time.time();\n",
    "    image_src = cv2.imread(input_img)\n",
    "    pred_dict = estimator(image_src, masks=False, keypoints=True)\n",
    "#     masks = estimator.get_masks(pred_dict['estimator_m'], score_threshold=0.99)\n",
    "    keypoints = estimator.get_keypoints(pred_dict['estimator_k'], score_threshold=0.97)\n",
    "    if len(keypoints) == 0:\n",
    "        print(\"not found\");\n",
    "#     print(f\"masks : {masks}\");\n",
    "#     print(f\"keypoints : {keypoints}\");\n",
    "    nose = keypoints[0][0][:2];\n",
    "    eye_l = keypoints[0][1][:2];\n",
    "    eye_r = keypoints[0][2][:2];\n",
    "    ear_l = keypoints[0][3][:2];\n",
    "    ear_r = keypoints[0][4][:2];\n",
    "    # add later...\n",
    "    ankle_r = keypoints[0][16][:2];\n",
    "    df = pd.DataFrame({\"nose\":nose, \"eye_l\":eye_l, \"eye_r\":eye_r, \n",
    "                       \"ear_l\":ear_l, \"ear_r\":ear_r, \"ankle_r\":ankle_r}, index=[\"x\",\"y\"]);\n",
    "    print(df);\n",
    "\n",
    "    image_dst = cv2.cvtColor(image_src, cv2.COLOR_BGR2GRAY)\n",
    "#     image_dst = cv2.merge([image_dst] * 3)\n",
    "#     overlay_m = draw_masks(image_dst, masks, color=(0, 255, 0), alpha=0.5)\n",
    "    overlay_k = draw_body_connections(image_src, keypoints, thickness=4, alpha=0.7)\n",
    "    overlay_k = draw_keypoints(overlay_k, keypoints, radius=5, alpha=0.8)\n",
    "    image_dst = overlay_k;\n",
    "\n",
    "    cv2.imwrite(outfile, image_dst);\n",
    "#     print(f\"Image {input_img} estimating time : {time.time()-start}\\n\");\n",
    "#     times.append(time.time()-start);\n",
    "    #while True:\n",
    "    #    cv2.imshow('Image Demo', image_dst)\n",
    "    #    if cv2.waitKey(1) & 0xff == 27: # exit if pressed `ESC`\n",
    "    #        break\n",
    "#     cv2.destroyAllWindows();\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     for i in [\"5_bg\", \"11_bg\"]:\n",
    "    for i in [5,6,7,9,10,11,12,13]:\n",
    "        main(f\"inputs/{i}.jpg\", f\"outputs/processed_{i}.png\");\n",
    "#     print(f\"Average time : {sum(times)/len(times)}\");\n",
    "#     main(\"media/example3.png\", \"outputs/processed_standard.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
